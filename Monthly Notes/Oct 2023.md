## openai

- Exciting news for @OpenAI devs: we are close to a 1.0 release of the OpenAI Python SDK ðŸŽŠ. You can test the beta version of 1.0 today, we would love to get your early feedback! [changelog](https://twitter.com/StainlessAPI/status/1709650331972379060)
- sama podcast on joe rogan experience

## Models

- Small
  - [ Stable LM 3B: Bringing Sustainable, High-Performance LMs to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices) https://news.ycombinator.com/item?id=37739965
  - Rift coder 7B https://twitter.com/morph_labs/status/1709288051195998375 finetune of ???
  - [CollectiveCognition v1](https://twitter.com/Teknium1/status/1709750388528939473) finetune of Mistral 7B
  - [TinyLanguage Models come of age](https://news.ycombinator.com/item?id=37787350)
- ?
  - Reka Yasa-1 Multimodal LLM ([tweet](https://twitter.com/YiTayML/status/1709265184576204820), [blog](https://reka.ai/announcing-our-multimodal-ai-assistant/) - natively supports images, audio, and short video clips as inputs. )
    - Retrieval augmented generation - Yasa can be taught to understand private datasets. Our API and on-premise deployment setup allows seamless integration of internal datasets of any modality type.
    - Code Interpreter - Yasa is more than just a passive AI assistant; it has the capability to actively execute code. This feature is enabled via a simple flag. When active, Yasa automatically identifies the code block within its response, executes the code, and appends the result at the end of the block.

Below is an example of the featureâ€™s ability to perform arithmetic operations, analyze spreadsheets, or create visualizations.

## open source projects and templates

- Daniel Grossâ€™ [LocalPilot](https://x.com/danielgross/status/1708855228122964291?s=20)- â€œIn my experience, 7b isn't usefully fast enough for autocomplete on M1, but M2 Max is the punctuated equilibrium; it's suddenly good enough. (34b quantized models are fast enough for Q&A.)â€œ
- [headshot AI project](https://x.com/svpino/status/1711003548073504886?s=20)
	- https://twitter.com/leap_api

## other launches

- Mistral 7B, Llama2 13B, Code Llama 34B, and Llama2 70B models supported [https://blog.perplexity.ai/blog/introducing-pplx-api](https://blog.perplexity.ai/blog/introducing-pplx-api "https://blog.perplexity.ai/blog/introducing-pplx-api")
  - currently included with perplexity pro, no $/token (for now? I'm assuming only in public beta, that won't scale)
  - really leans into openAI api compatibility. They actually just use the openai python client. All you have to do is switch api_base, api_key, and model to point to perplexity to switch an application from openai to perplexity in python
  - (thanks @danjl on Latent Space Discord)

## Papers and Good Reads

- Models
  - [Efficient streaming language models with attention sinks](https://github.com/mit-han-lab/streaming-llm) ([HN](https://news.ycombinator.com/item?id=37740932#37742452))
  - [Expressive text-to-image generation with rich text](https://rich-text-to-image.github.io/) ([HN](https://news.ycombinator.com/item?id=37770260)) - being able to modify generated images by modifying text using fonts and text colors. going from words -> token maps (masks).
    - [Notable criticism of this method over regular prompting](https://news.ycombinator.com/item?id=37772250)
  - [FontoGen](https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font) - Â The model takes a font description as an input, and produces a font file as an output.
- Prompting
  - emotional jailbreaks work.Â [https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760) "This is very important to my career" and [the dead grandma jailbreak](https://news.ycombinator.com/item?id=37743759)
  - [https://arxiv.org/abs/2310.04406v1](https://arxiv.org/abs/2310.04406v1 "https://arxiv.org/abs/2310.04406v1") 94.4 on HumanEval with gpt4 86.9 on HumanEval with gpt3.5 wild
- RAG
  - [Vector database is not a separate database category](https://nextword.substack.com/p/vector-database-is-not-a-separate) ([HN](https://news.ycombinator.com/item?id=37747534))
  - [ Choosing vector database: a side-by-side comparison](https://benchmark.vectorview.ai/vectordbs.html) ([HN](https://news.ycombinator.com/item?id=37764489))
    - "Everyone I talk to who is building some vector db based thing sooner or later realizes they also care about the features of a full-text search engine.
    - They care about filtering, they care to some degree about direct lexical matches, they care about paging, getting groups / facet counts, etc.
    - Vectors, IMO, are just one feature that a regular search engine should have. IMO currently Vespa does the best job of this, though lately it seems Lucene (Elasticsearch and Opensearch) are really working hard to compete"
  - [Vespa.ai is spinning out of Yahoo as a separate company](https://blog.vespa.ai/vespa-is-becoming-its-own-company/)
- Evals
  - [Evaluating LLMs is a minefield](https://twitter.com/random_walker/status/1709583031001124889)
- Efficiency
  - [Running Stable Diffusion XL 1.0 in 298MB of RAM](https://github.com/vitoplantamura/OnnxStream/tree/846da873570a737b49154e8f835704264864b0fe)
    - OnnxStream is based on the idea of decoupling the inference engine from the component responsible of providing the model weights, which is a class derived fromÂ `WeightsProvider`. AÂ `WeightsProvider`Â specialization can implement any type of loading, caching and prefetching of the model parameters. For example a customÂ `WeightsProvider`Â can decide to download its data from an HTTP server directly, without loading or writing anything to disk (hence the word "Stream" in "OnnxStream"). Two defaultÂ `WeightsProviders`Â are available:Â `DiskNoCache`Â andÂ `DiskPrefetch`.
  - Mistral 7B outperforms Llama 13B on all tested benchmarks - guide showing how to fine-tune it cost-effectively using QLoRA ([brev tweet](https://twitter.com/HarperSCarroll/status/1709000201963532429))
  - [LLMs overview from Flyte](https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms)

## Fundraising

- Modal Labs Series A
	- https://x.com/modal_labs/status/1711748224610943163?s=20
- Induced AI $2.3m seed
  - We let anyone create virtual AI workers that can automate the execution of workflows on a browser in the cloud with human-like reasoning.
  - https://twitter.com/aryxnsharma/status/1709289742310010970

## prior discussion

- watermarking
  - researchers broke all watermarks? https://news.ycombinator.com/item?id=37767633
  - Truepic C2PA content credentials + Huggingface https://twitter.com/mmitchell_ai/status/1710123404706378233

## memes

- grandma is the new sudo https://twitter.com/latentspacepod/status/1708982643294146690
- its a rock https://x.com/itsmingjie/status/1709039235913719973?s=46&t=90xQ8sGy63D2OtiaoGJuww

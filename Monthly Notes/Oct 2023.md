
## Models

- Small
	- [ Stable LM 3B: Bringing Sustainable, High-Performance LMs to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices) https://news.ycombinator.com/item?id=37739965
	- Rift coder 7B https://twitter.com/morph_labs/status/1709288051195998375


## open source projects and templates


- Daniel Gross’ [LocalPilot](https://x.com/danielgross/status/1708855228122964291?s=20)- “In my experience, 7b isn't usefully fast enough for autocomplete on M1, but M2 Max is the punctuated equilibrium; it's suddenly good enough. (34b quantized models are fast enough for Q&A.)“

## other launches

- Mistral 7B, Llama2 13B, Code Llama 34B, and Llama2 70B models supported [https://blog.perplexity.ai/blog/introducing-pplx-api](https://blog.perplexity.ai/blog/introducing-pplx-api "https://blog.perplexity.ai/blog/introducing-pplx-api")
	- currently included with perplexity pro, no $/token (for now? I'm assuming only in public beta, that won't scale)
	- really leans into openAI api compatibility. They actually just use the openai python client. All you have to do is switch api_base, api_key, and model to point to perplexity to switch an application from openai to perplexity in python
	- (thanks @danjl on Latent Space Discord)

## Papers and Good Reads

- Models
	- [Efficient streaming language models with attention sinks](https://github.com/mit-han-lab/streaming-llm) ([HN](https://news.ycombinator.com/item?id=37740932#37742452))
	- Reka Yasa-1 Multimodal LLM ([tweet](https://twitter.com/YiTayML/status/1709265184576204820))
- Prompting
	- emotional jailbreaks work. [https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760) "This is very important to my career" and [the dead grandma jailbreak](https://news.ycombinator.com/item?id=37743759)
- RAG
	- [Vector database is not a separate database category](https://nextword.substack.com/p/vector-database-is-not-a-separate) ([HN](https://news.ycombinator.com/item?id=37747534))
- Efficiency
	- [Running Stable Diffusion XL 1.0 in 298MB of RAM](https://github.com/vitoplantamura/OnnxStream/tree/846da873570a737b49154e8f835704264864b0fe)
	- Mistral 7B outperforms Llama 13B on all tested benchmarks -  guide showing how to fine-tune it cost-effectively using QLoRA ([brev tweet](https://twitter.com/HarperSCarroll/status/1709000201963532429))

## Fundraising

- Induced AI $2.3m seed
	- We let anyone create virtual AI workers that can automate the execution of workflows on a browser in the cloud with human-like reasoning.
	- https://twitter.com/aryxnsharma/status/1709289742310010970

## memes

- grandma is the new sudo https://twitter.com/latentspacepod/status/1708982643294146690
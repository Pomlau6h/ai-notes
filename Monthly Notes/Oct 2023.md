
- https://www.thurrott.com/cloud/290661/report-github-copilot-loses-an-average-of-20-per-user-per-month
- https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/
- https://blog.replit.com/replit-code-v1_5
- model transparency?


## openai

- Exciting news for @OpenAI devs: we are close to a 1.0 release of the OpenAI Python SDK ðŸŽŠ. You can test the beta version of 1.0 today, we would love to get your early feedback! [changelog](https://twitter.com/StainlessAPI/status/1709650331972379060)
- sama podcast on joe rogan experience
- finetuning ui has end to end job creation, no code required ([tweet](https://twitter.com/OfficialLoganK/status/1710434050274734110) - [not our fault](https://x.com/OfficialLoganK/status/1710680533574045781?s=20))
- [OpenAIâ€™s technology explained](https://twitter.com/OfficialLoganK/status/1712483165380415828)
- Collection of [ChatGPT System Prompts](https://news.ycombinator.com/item?id=37879077) including Voice and Custom Instructions

## Models

- Large
  - Lemur-70B & Lemur-70B-Chat: ðŸš€Open & SOTA Foundation Models for Language Agents! The closest open model to GPT-3.5 on 15 agent tasks ([tweet](https://twitter.com/yihengxu_/status/1712537543688990940), [paper](https://arxiv.org/abs/2310.06830))
- Medium
	- Announcing Open Hermes 2!! A continuation of the Hermes series of models, now built on Mistral 7B! The Hermes 2 model was trained on 900,000 instructions, and surpasses all previous versions of Hermes 13B and below, and matches 70B on some benchmarks! Hermes 2 changes the game with strong multiturn chat skills, system prompt capabilities, and uses ChatML format. It's quality, diversity and scale is unmatched in the current OS LM landscape. Not only does it do well in benchmarks, but also in unmeasured capabilities, like Roleplaying, Tasks, and more. [https://fxtwitter.com/Teknium1/status/1714010838959612329](https://fxtwitter.com/Teknium1/status/1714010838959612329 "https://fxtwitter.com/Teknium1/status/1714010838959612329")
- Small
  - [ Stable LM 3B: Bringing Sustainable, High-Performance LMs to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices) https://news.ycombinator.com/item?id=37739965
  - Rift coder 7B https://twitter.com/morph_labs/status/1709288051195998375 finetune of ???
  - [CollectiveCognition v1](https://twitter.com/Teknium1/status/1709750388528939473) finetune of Mistral 7B
  - [TinyLanguage Models come of age](https://news.ycombinator.com/item?id=37787350)
  - Adept multimodal model ([twitter]([https://twitter.com/AdeptAILabs/status/1714682075763405257](https://twitter.com/AdeptAILabs/status/1714682075763405257 "https://twitter.com/AdeptAILabs/status/1714682075763405257"))) - Fuyu-8B
	  - compare to nougat  https://facebookresearch.github.io/nougat/

- ?
  - Reka Yasa-1 Multimodal LLM ([tweet](https://twitter.com/YiTayML/status/1709265184576204820), [blog](https://reka.ai/announcing-our-multimodal-ai-assistant/) - natively supports images, audio, and short video clips as inputs. )
    - Retrieval augmented generation - Yasa can be taught to understand private datasets. Our API and on-premise deployment setup allows seamless integration of internal datasets of any modality type.
    - Code Interpreter - Yasa is more than just a passive AI assistant; it has the capability to actively execute code. This feature is enabled via a simple flag. When active, Yasa automatically identifies the code block within its response, executes the code, and appends the result at the end of the block.
- [PaLI-3 Vision Language Models](https://arxiv.org/abs/2310.09199)Â ([arxiv.org](https://news.ycombinator.com/from?site=arxiv.org))
- TimeGPT https://news.ycombinator.com/item?id=37874891

Below is an example of the featureâ€™s ability to perform arithmetic operations, analyze spreadsheets, or create visualizations.

## open source projects and templates

- Daniel Grossâ€™ [LocalPilot](https://x.com/danielgross/status/1708855228122964291?s=20)- â€œIn my experience, 7b isn't usefully fast enough for autocomplete on M1, but M2 Max is the punctuated equilibrium; it's suddenly good enough. (34b quantized models are fast enough for Q&A.)â€œ
- [headshot AI project](https://x.com/svpino/status/1711003548073504886?s=20)
  - https://twitter.com/leap_api
- Llama 2 in C https://x.com/karpathy/status/1710061549677613469?s=46&t=6FDPaNxZcbSsELal6Sv7Ug
  - https://news.ycombinator.com/item?id=37785442
- [ SlowLlama: Finetune llama2-70B and codellama on MacBook Air without quantization](https://github.com/okuvshynov/slowllama)
- Mistal finetunes
	- https://dadjokes.dfdx.me/
- [select LLM, and GPU, and see if can run locally](https://x.com/victormustar/status/1712754193784520966?s=20)

## other launches

- Langchain langserve - https://twitter.com/LangChainAI/status/1712526285313102091
- Mistral 7B, Llama2 13B, Code Llama 34B, and Llama2 70B models supported [https://blog.perplexity.ai/blog/introducing-pplx-api](https://blog.perplexity.ai/blog/introducing-pplx-api "https://blog.perplexity.ai/blog/introducing-pplx-api")
  - currently included with perplexity pro, no $/token (for now? I'm assuming only in public beta, that won't scale)
  - really leans into openAI api compatibility. They actually just use the openai python client. All you have to do is switch api_base, api_key, and model to point to perplexity to switch an application from openai to perplexity in python
  - (thanks @danjl on Latent Space Discord)
- [ Show HN: Shortbread â€“Â Create AI comics in minutes](https://shortbread.ai/)Â ([shortbread.ai](https://news.ycombinator.com/from?site=shortbread.ai))
  - great demo of what a nice stable diffusion 1.5 app can do today
- [SiFive Rolls Out RISC-V Cores Aimed at Generative AI and ML](https://www.allaboutcircuits.com/news/sifive-rolls-out-risc-v-cores-aimed-at-generative-ai-and-ml/) https://news.ycombinator.com/item?id=37911544
- [Show HN: Riffusion with Lyrics](https://www.riffusion.com/)Â ([riffusion.com](https://news.ycombinator.com/from?site=riffusion.com))
	- https://news.ycombinator.com/item?id=37914425

## Papers and Good Reads

- Models
  - [Efficient streaming language models with attention sinks](https://github.com/mit-han-lab/streaming-llm) ([HN](https://news.ycombinator.com/item?id=37740932#37742452))
  - [Expressive text-to-image generation with rich text](https://rich-text-to-image.github.io/) ([HN](https://news.ycombinator.com/item?id=37770260)) - being able to modify generated images by modifying text using fonts and text colors. going from words -> token maps (masks).
    - [Notable criticism of this method over regular prompting](https://news.ycombinator.com/item?id=37772250)
  - [FontoGen](https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font) - Â The model takes a font description as an input, and produces a font file as an output.
- Prompting
  - emotional jailbreaks work.Â [https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760) "This is very important to my career" and [the dead grandma jailbreak](https://news.ycombinator.com/item?id=37743759)
  - [https://arxiv.org/abs/2310.04406v1](https://arxiv.org/abs/2310.04406v1 "https://arxiv.org/abs/2310.04406v1") 94.4 on HumanEval with gpt4 86.9 on HumanEval with gpt3.5 wild
- RAG
  - https://arxiv.org/pdf/2310.05029
  - RAG vs Long Context
    - https://x.com/_philschmid/status/1710575136657600958?s=46&t=6FDPaNxZcbSsELal6Sv7Ug
    - https://arxiv.org/abs/2310.03025
  - [Vector database is not a separate database category](https://nextword.substack.com/p/vector-database-is-not-a-separate) ([HN](https://news.ycombinator.com/item?id=37747534))
  - Text embeddings can be inverted ([twitter](https://x.com/jxmnop/status/1712562908133999069?s=20))
  - MemGPT - LLMs as operating systems ([twitter](https://x.com/iScienceLuvr/status/1712747095676117155?s=20), [site](https://memgpt.ai/), arxiv, [HN](https://news.ycombinator.com/item?id=37894403))
  - MemWalker - Long context models are popular, but is it the final solution to long text reading? We introduce a fundamentally different method, MemWalker: 1. Build a data structure (memory tree) 2. Traverse it via LLM prompting Outperforms long context, retrieval, & recurrent baselines. (1/n) ([tweet](https://twitter.com/__howardchen/status/1711584916708938042))
  - [ Choosing vector database: a side-by-side comparison](https://benchmark.vectorview.ai/vectordbs.html) ([HN](https://news.ycombinator.com/item?id=37764489))
    - "Everyone I talk to who is building some vector db based thing sooner or later realizes they also care about the features of a full-text search engine.
    - They care about filtering, they care to some degree about direct lexical matches, they care about paging, getting groups / facet counts, etc.
    - Vectors, IMO, are just one feature that a regular search engine should have. IMO currently Vespa does the best job of this, though lately it seems Lucene (Elasticsearch and Opensearch) are really working hard to compete"
  - [Vespa.ai is spinning out of Yahoo as a separate company](https://blog.vespa.ai/vespa-is-becoming-its-own-company/)
- Evals
  - [Evaluating LLMs is a minefield](https://twitter.com/random_walker/status/1709583031001124889)
    - the reports of ChatGPT having a liberal bias were a result of oversensitive prompts
    - GPT4 passing the bar exam and USMLE is a sign of contamination
      - "[OpenAIâ€™s method to detect contamination is superficial and sloppy](https://www.aisnakeoil.com/p/gpt-4-and-professional-benchmarks)"
- Efficiency
  - [Running Stable Diffusion XL 1.0 in 298MB of RAM](https://github.com/vitoplantamura/OnnxStream/tree/846da873570a737b49154e8f835704264864b0fe)
    - OnnxStream is based on the idea of decoupling the inference engine from the component responsible of providing the model weights, which is a class derived fromÂ `WeightsProvider`. AÂ `WeightsProvider`Â specialization can implement any type of loading, caching and prefetching of the model parameters. For example a customÂ `WeightsProvider`Â can decide to download its data from an HTTP server directly, without loading or writing anything to disk (hence the word "Stream" in "OnnxStream"). Two defaultÂ `WeightsProviders`Â are available:Â `DiskNoCache`Â andÂ `DiskPrefetch`.
  - Mistral 7B outperforms Llama 13B on all tested benchmarks - guide showing how to fine-tune it cost-effectively using QLoRA ([brev tweet](https://twitter.com/HarperSCarroll/status/1709000201963532429))
  - [LLMs overview from Flyte](https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms)
  - [OpenAI is too cheap to beat](https://generatingconversation.substack.com/p/openai-is-too-cheap-to-beat) - "At $366K ($166K AWS + $200K talent), weâ€™re paying around $80 per-fine-tuning run, about 8-20x higher than what weâ€™re paying OpenAI!"
    - [Open, general-purpose LLM companies might not be viable](https://www.interconnects.ai/p/are-open-llms-viable)
- Multimodality
	- LMMs > LLMs
	- [Multi-modal prompt injection image attacks against GPT-4V](https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/)Â ([simonwillison.net](https://news.ycombinator.com/from?site=simonwillison.net))
	- [Multimodality and Large Multimodal Models (LMMs)](https://huyenchip.com//2023/10/10/multimodal.html)
- [The Killer Use Case for LLMs Is Summarization](https://www.sebastianmellen.com/post/2023/the-killer-use-case-for-llms-is-summarization/)Â ([sebastianmellen.com](https://news.ycombinator.com/from?site=sebastianmellen.com))
	- https://news.ycombinator.com/item?id=37946023

## Fundraising

- Modal Labs Series A
  - https://x.com/modal_labs/status/1711748224610943163?s=20
- Anyscale (Cursor.so) Seed
  - https://techcrunch.com/2023/10/11/anysphere-raises-8m-from-openai-to-build-an-ai-powered-ide/
- Induced AI $2.3m seed
  - We let anyone create virtual AI workers that can automate the execution of workflows on a browser in the cloud with human-like reasoning.
  - https://twitter.com/aryxnsharma/status/1709289742310010970

## prior discussion

- watermarking
  - researchers broke all watermarks? https://news.ycombinator.com/item?id=37767633
  - Truepic C2PA content credentials + Huggingface https://twitter.com/mmitchell_ai/status/1710123404706378233
- Custom Instructions - nice template https://github.com/spdustin/ChatGPT-AutoExpert/
- Pmarca [Techno-Optimist Manifesto](https://a16z.com/the-techno-optimist-manifesto/) 
	- [Marc Andreessen's AI manifesto hurts his own cause](https://www.axios.com/2023/10/17/marc-andreessens-ai-manifesto-hurts-his-own-cause)Â ([axios.com](https://news.ycombinator.com/from?site=axios.com))

## memes

- grandma is the new sudo https://twitter.com/latentspacepod/status/1708982643294146690
- its a rock https://x.com/itsmingjie/status/1709039235913719973?s=46&t=90xQ8sGy63D2OtiaoGJuww


## why radiologists didnt go away

https://twitter.com/bengoldhaber/status/1611074716927922177?s=46&t=fAgqJB7GXbFmnqQPe7ss6w



### where are all the ai engineers?

- ai skepticism
- ??? skepticism (i said this on cogrev podcast)
- self skepticism


## transofmrers are eating the world

- karpathy observation
- tayml model architecture chart

### creative fiction


harrison bergeron story but with ai being shackled to human preferences

### illustrating  langchain concepts

- https://blog.langchain.dev/agent-toolkits/
	- By agents we mean a system that uses an LLM to decide what actions to take in a repeated manner, where future decisions are made based on observing the outcome of previous actions.

## on the Bitter lesson

- https://archive.is/FEGf1 In an influential 2019 [essay](https://archive.is/o/FEGf1/https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson.pdf), the A.I. researcher Richard Sutton explains that early speech-recognition programs were loaded with specialized linguistics knowledge—not just about syntax, grammar, and phonetics but about how the shape of the human mouth constrained what sounds were possible. Despite their sophistication, these programs didn’t work very well. In the nineteen-seventies, there was a turn toward statistical methods, which dropped expert knowledge in favor of patterns learned from data—for instance, about which sounds and words tended to go together. The success of that approach bled out into the rest of A.I., leading the field to center much of its effort on statistics drawn from huge amounts of data.
	- response https://staff.fnwi.uva.nl/m.welling/wp-content/uploads/Model-versus-Data-AI-1.pdf


## alibi and the context of infinity

gpt4 demo
anthropic https://news.ycombinator.com/item?id=35904773

alibi, lex and position interpolation https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/


## data augmented retrieval

llamaindex
vs 
langchain

approaches

https://arxiv.org/abs/2005.11401
Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks


### ways to augment foundation models

- RLHF/Finetuning (ylecun cake analogy)
	- focus model
	- https://magazine.sebastianraschka.com/p/finetuning-large-language-models#%C2%A7in-context-learning-and-indexing
- stuff examples in context
	- search similar knowledge and hallucinate/summarize
- [ReACT](https://www.geoffreylitt.com/2023/01/29/fun-with-compositional-llms-querying-basketball-stats-with-gpt-3-statmuse-langchain.html) 
	- augment capability to get knowledge
	- fixie, zapier


## ai detection tools

ai cheating detection
perplexity with gptzero
- https://github.com/BurhanUlTayyab/GPTZero
detectgpt
https://twitter.com/chelseabfinn/status/1618822672489779201?s=46&t=REbUC7rjX6u_QSXYIzeDLw

https://twitter.com/_eric_mitchell_/status/1618820358043475969?s=46&t=REbUC7rjX6u_QSXYIzeDLw

https://decrypt.co/149826/openai-quietly-shutters-its-ai-detection-tool

## waves in AI products

- text
	- first it was headlines
	- then it was copywriting/product description
	- then its fiction
- first it was architecture
- then it was dreambooth pfps
- then it was settings (levelsio)
- then it was products
	- Pebbley -  inpainting for product placement https://twitter.com/alfred_lua/status/1610641101265981440?s=46&t=RMPT1jJedELVkL2Aby-40g
	- Flair AI https://twitter.com/mickeyxfriedman/status/1613251965634465792
	- https://www.stylized.ai/
	- booth ai https://twitter.com/nick_locascio?s=21&t=0HHr1d45XGJ24amPDvbz5w


### interviews

- dust.tt
- goodside
- sharif shameem
- orchard.ink guys
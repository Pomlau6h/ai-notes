
- origins and recruiting researchers - 2016 https://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/
- GPT2 and leadership team - 2020 https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/
- openai-anthropic split was over the GPT3 api https://archive.is/YTOeD#selection-333.226-337.82
- openai rebrand and identity https://twitter.com/asselinpaul/status/1636938731398787074
- elon and sama split - 2023 https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai
- july 2022-march 2023 shipping velocity https://twitter.com/E0M/status/1635727471747407872
- march 2023 - turned off codex and then changed their minds  https://twitter.com/deepfates/status/1638212305887567873?s=20
- apr 2023 - valued at 27b with 400 employees internally https://twitter.com/frantzfries/status/1647976195693182978?s=46&t=90xQ8sGy63D2OtiaoGJuww
- may 2023 - losing 500m a year? https://twitter.com/amir/status/1654218677074681858?s=20

## ilya sutskever

- 2 core ideas behind openai https://twitter.com/radekosmulski/status/1639123080646897664
	- Unsupervised learning through compression. Turns out, if you want to compress a lot of data, you have to discover the secrets that live in it.
	- Reinforcement learning is impt. But the RL from playing Dota merged with Transformers to give us Reinforcement Learning from Human Feedback. 
	- Bigger is better. predict text + scale => world model